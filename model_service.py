# model_service.py
import pandas as pd
import numpy as np
import joblib
import os
import warnings
import tensorflow as tf
from datetime import timedelta

# ==========================================
# ğŸš‘ [è¨­å®š] æŠ‘åˆ¶è­¦å‘Šèˆ‡ç’°å¢ƒè¨­å®š
# ==========================================
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"  # é æ¸¬æ™‚ä½¿ç”¨ CPU å³å¯
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
warnings.filterwarnings("ignore")

# ==========================================
# âš™ï¸ è¨­å®šå¸¸æ•¸
# ==========================================
# å¿…é ˆèˆ‡ app_utils.py ä¸­çš„è¨­å®šä¸€è‡´ï¼Œç”¨ä¾†é‚„åŸæ•¸å€¼
DESIGN_PEAK_LOAD_KW = 20.0 

MODEL_FILES = {
    "config": "hybrid_residual.pkl",    # å­˜æ”¾ Scaler, Columns, Params
    "lgbm": "lgbm_residual.pkl",        # æ®˜å·®ä¿®æ­£æ¨¡å‹
    "lstm": "lstm_hybrid.keras",        # è¶¨å‹¢é æ¸¬æ¨¡å‹
    "history_data": "final_training_data_with_humidity.csv" # é è¨­æ­·å²è³‡æ–™
}

# ==========================================
# ğŸ› ï¸ ç‰¹å¾µå·¥ç¨‹ (å®Œå…¨è¤‡è£½è¨“ç·´è…³æœ¬é‚è¼¯)
# ==========================================

def add_strict_features(df):
    """LightGBM ç”¨çš„ç‰¹å¾µ (å°æ‡‰è¨“ç·´ç¨‹å¼ç¢¼)"""
    df = df.copy()
    
    # äº¤äº’ä½œç”¨èˆ‡çµ±è¨ˆ
    df["temp_squared"] = df["temperature"] ** 2
    df["temp_humidity"] = df["temperature"] * df["humidity"]
    
    # æ»¾å‹•å¹³å‡ (æº«åº¦)
    df["temp_roll_24"] = df["temperature"].rolling(window=24, min_periods=1).mean()
    df["temp_roll_72"] = df["temperature"].rolling(window=72, min_periods=1).mean()
    
    # æ»¯å¾Œç‰¹å¾µ (Lags)
    df["lag_24"] = df["power"].shift(24)
    df["lag_48"] = df["power"].shift(48)
    df["lag_168"] = df["power"].shift(168)
    
    # æ»¾å‹•ç‰¹å¾µ (é›»åŠ›)
    # è¨“ç·´ä»£ç¢¼ä¸­ä½¿ç”¨ .shift(24) é¿å… Data Leakage
    df["rolling_mean_24h"] = df["power"].shift(24).rolling(window=24, min_periods=1).mean()
    df["rolling_max_24h"] = df["power"].shift(24).rolling(window=24, min_periods=1).max()
    df["rolling_min_24h"] = df["power"].shift(24).rolling(window=24, min_periods=1).min()
    df["rolling_mean_7d"] = df["power"].shift(24).rolling(window=168, min_periods=1).mean()
    
    df["diff_24_48"] = df["power"].shift(24) - df["power"].shift(48)
    
    return df

def add_engineering_features(df):
    """LSTM ç”¨çš„ç‰¹å¾µ (å°æ‡‰è¨“ç·´ç¨‹å¼ç¢¼)"""
    df = df.copy()
    
    df["temp_squared"] = df["temperature"] ** 2
    
    df["lag_24h"] = df["power"].shift(24)
    df["lag_168h"] = df["power"].shift(168)
    
    # LSTM ç‰¹å¾µï¼šä½¿ç”¨ shift(1) ä»£è¡¨çœ‹çš„æ˜¯ã€Œä¸Šä¸€å°æ™‚ã€ä»¥å‰çš„æ•¸æ“š
    df["rolling_mean_3h"] = df["power"].shift(1).rolling(window=3, min_periods=1).mean()
    df["rolling_mean_24h"] = df["power"].shift(1).rolling(window=24, min_periods=1).mean()
    
    return df

# ==========================================
# ğŸ§  æ ¸å¿ƒé æ¸¬é‚è¼¯
# ==========================================

def load_resources_and_predict(input_df=None):
    """
    è¼‰å…¥æ¨¡å‹ä¸¦åŸ·è¡Œæœªä¾† 24 å°æ™‚çš„é æ¸¬
    åŒ…å«ï¼šè³‡æ–™æ¸…æ´—ã€é »ç‡é‡å–æ¨£(Resampling)ã€æ•¸å€¼é‚„åŸã€Autoregressive é æ¸¬
    """
    print("ğŸš€ Starting Hybrid Prediction Service...")
    
    # 1. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    missing_files = [f for n, f in MODEL_FILES.items() if not os.path.exists(f)]
    if missing_files:
        print(f"âŒ Missing files: {missing_files}")
        return None, None

    try:
        # 2. è¼‰å…¥æ¨¡å‹èˆ‡è¨­å®šæª”
        config = joblib.load(MODEL_FILES['config'])
        lgbm_model = joblib.load(MODEL_FILES['lgbm'])
        lstm_model = tf.keras.models.load_model(MODEL_FILES['lstm'])
        
        # å¾ config é‚„åŸ Scaler å’Œ æ¬„ä½åç¨±
        scaler_seq = config['scaler_seq']
        scaler_direct = config['scaler_direct']
        scaler_target = config['scaler_target']
        
        lstm_seq_cols = config['lstm_seq_cols']
        lstm_direct_cols = config['lstm_direct_cols']
        lgbm_feature_cols = config['lgbm_feature_cols']
        lookback_hours = config['lookback_hours'] # é€šå¸¸æ˜¯ 168

        print("âœ… Models and Config loaded successfully.")

        # 3. æº–å‚™æ­·å²è³‡æ–™ (Context)
        if input_df is not None and not input_df.empty:
            history_df = input_df.copy()
        else:
            # è‹¥ç„¡å¤–éƒ¨è¼¸å…¥ï¼Œè®€å–é è¨­ CSV
            history_df = pd.read_csv(MODEL_FILES['history_data'])
            if 'datetime' in history_df.columns:
                history_df['timestamp'] = pd.to_datetime(history_df['datetime'])
            elif 'timestamp' in history_df.columns:
                history_df['timestamp'] = pd.to_datetime(history_df['timestamp'])
            history_df = history_df.set_index('timestamp').sort_index()

        # -----------------------------------------------------------
        # ğŸš‘ [è³‡æ–™æ¸…æ´—å€] - è§£æ±ºå°æ¥å•é¡Œçš„æ ¸å¿ƒ
        # -----------------------------------------------------------
        
        # A. æ¬„ä½åç¨±æ˜ å°„ (UI: power_kW -> Model: power)
        if 'power_kW' in history_df.columns:
            history_df = history_df.rename(columns={'power_kW': 'power'})
        
        # ç¢ºä¿å¿…è¦æ¬„ä½å­˜åœ¨
        required_cols = ['power', 'temperature', 'humidity']
        for col in required_cols:
            if col not in history_df.columns:
                # è‹¥ç¼ºæº«æ¿•åº¦ï¼Œçµ¦äºˆé è¨­å€¼ä»¥å…å ±éŒ¯
                if col == 'temperature': history_df[col] = 25.0
                elif col == 'humidity': history_df[col] = 70.0
                else: raise ValueError(f"Missing column: {col}")
        
        history_df = history_df[required_cols] # åªä¿ç•™éœ€è¦çš„æ¬„ä½

        # B. é »ç‡é‡å–æ¨£ (Resampling) - è§£æ±º 15min è³‡æ–™å•é¡Œ
        # å¼·åˆ¶è½‰ç‚ºæ¯å°æ™‚ä¸€ç­† (å–å¹³å‡)ï¼Œä¸¦å¡«è£œç©ºç¼º
        history_df = history_df.resample('H').mean().ffill()

        # C. æ•¸å€¼ç¸®æ”¾æª¢æ¸¬ (Scaling Check) - è§£æ±º x20 å€ç‡å•é¡Œ
        # æª¢æŸ¥é‚è¼¯ï¼šå¦‚æœæ•¸æ“šå¹³å‡å€¼å¾ˆå¤§ (ä¾‹å¦‚ > 2.0)ï¼Œå¾ˆæœ‰å¯èƒ½æ˜¯å·²ç¶“è¢« UI æ”¾å¤§éçš„
        # è¨“ç·´è³‡æ–™é€šå¸¸åœ¨ 0~1 ä¹‹é–“ (åŸå§‹ CSV)
        is_ui_scaled = False
        if history_df['power'].mean() > 2.0: 
            print("âš ï¸ Detected scaled input (UI scale). Reverting to model scale...")
            history_df['power'] = history_df['power'] / DESIGN_PEAK_LOAD_KW
            is_ui_scaled = True
        
        # -----------------------------------------------------------
        
        # 4. é æ¸¬è¿´åœˆæº–å‚™
        buffer_size = 500 # å–è¶³å¤ é•·åº¦ä»¥è¨ˆç®— Lag
        current_df = history_df.iloc[-buffer_size:].copy()
        future_predictions = []
        last_timestamp = current_df.index[-1]
        
        print(f"â±ï¸ Predicting future from: {last_timestamp}")

        # æ¨¡æ“¬æœªä¾†å¤©æ°£ (ä½¿ç”¨æœ€å¾Œä¸€ç­†å¤©æ°£å»¶çºŒï¼Œå¯¦éš›å¯æ¥ API)
        last_temp = current_df['temperature'].iloc[-1]
        last_hum = current_df['humidity'].iloc[-1]

        # 5. é€å°æ™‚é æ¸¬æœªä¾† 24 å°æ™‚ (Autoregressive Loop)
        for i in range(1, 25): 
            next_time = last_timestamp + timedelta(hours=i)
            
            # --- å»ºç«‹æš«å­˜ DataFrame (åŒ…å«éå» + ç¾åœ¨è¦é æ¸¬çš„é‚£ä¸€å°æ™‚) ---
            next_row = pd.DataFrame({
                'temperature': [last_temp], 
                'humidity': [last_hum],
                'power': [np.nan] # å¾…é æ¸¬
            }, index=[next_time])
            
            temp_df = pd.concat([current_df, next_row])
            
            # --- Step A: LSTM é æ¸¬ ---
            # è¨ˆç®—ç‰¹å¾µ
            df_lstm_feat = add_engineering_features(temp_df)
            
            # æº–å‚™è¼¸å…¥è³‡æ–™
            target_idx = -1
            seq_data = df_lstm_feat[lstm_seq_cols].iloc[target_idx-lookback_hours : target_idx].values
            direct_data = df_lstm_feat[lstm_direct_cols].iloc[target_idx : target_idx+1].values
            
            if len(seq_data) < lookback_hours:
                print("âš ï¸ Not enough history for LSTM lookback.")
                break

            # æ­£è¦åŒ– (Transform)
            X_seq = scaler_seq.transform(seq_data).reshape(1, lookback_hours, -1)
            X_direct = scaler_direct.transform(direct_data)
            
            # é æ¸¬
            lstm_pred_scaled = lstm_model.predict([X_seq, X_direct], verbose=0).flatten()[0]
            
            # åæ­£è¦åŒ– (é‚„åŸæˆ Model Scale çš„çœŸå¯¦å€¼)
            lstm_pred_real = scaler_target.inverse_transform([[lstm_pred_scaled]])[0][0]
            
            # --- Step B: LightGBM æ®˜å·®ä¿®æ­£ ---
            # è¨ˆç®—ç‰¹å¾µ (åŒ…å« LightGBM ç‰¹æœ‰çš„ lag ç‰¹å¾µ)
            df_lgbm_feat = add_strict_features(temp_df)
            current_lgbm_feat = df_lgbm_feat.iloc[[target_idx]].copy()
            
            # åŠ å…¥ LSTM é æ¸¬å€¼ä½œç‚ºç‰¹å¾µ
            current_lgbm_feat['lstm_pred'] = lstm_pred_real
            
            # é æ¸¬æ®˜å·®
            X_lgbm = current_lgbm_feat[lgbm_feature_cols]
            lgbm_residual = lgbm_model.predict(X_lgbm)[0]
            
            # --- Step C: æœ€çµ‚èåˆ ---
            final_pred = lstm_pred_real + lgbm_residual
            final_pred = max(0.0, final_pred) # ä¿®æ­£è² å€¼
            
            # å°‡é æ¸¬çµæœå¡«å› current_df (ä¾›ä¸‹ä¸€è¼ªé æ¸¬ä½¿ç”¨)
            current_df = pd.concat([current_df, pd.DataFrame({
                'temperature': [last_temp],
                'humidity': [last_hum],
                'power': [final_pred]
            }, index=[next_time])])
            
            # å„²å­˜çµæœ (å¦‚æœæ˜¯ UI ç¸®æ”¾éï¼Œé€™è£¡è¦ä¹˜å›å»ä»¥ä¾¿ UI é¡¯ç¤º)
            display_factor = DESIGN_PEAK_LOAD_KW if is_ui_scaled else 1.0
            
            future_predictions.append({
                "æ™‚é–“": next_time,
                "é æ¸¬å€¼": final_pred * display_factor,
                "LSTMåŸºç¤": lstm_pred_real * display_factor,
                "æ®˜å·®ä¿®æ­£": lgbm_residual * display_factor
            })

        # 6. æ•´ç†è¼¸å‡º
        result_df = pd.DataFrame(future_predictions).set_index("æ™‚é–“")
        
        # ç‚ºäº†ç•«åœ–ï¼Œå›å‚³æ­·å²è³‡æ–™ (ä¹Ÿè¦ä¹˜å›å€ç‡)
        ui_history_df = history_df.copy()
        if is_ui_scaled:
            ui_history_df['power'] = ui_history_df['power'] * DESIGN_PEAK_LOAD_KW
            
        # UI é æœŸæ¬„ä½æ˜¯ 'power_kW'
        ui_history_df = ui_history_df.rename(columns={'power': 'power_kW'})
        # åªå›å‚³æœ€å¾Œ 72 å°æ™‚çµ¦ UI ç•«åœ–
        ui_history_df = ui_history_df.iloc[-72:][['power_kW']]
        
        print("âœ… Prediction complete.")
        return result_df, ui_history_df

    except Exception as e:
        print(f"âŒ Prediction Error: {e}")
        import traceback
        traceback.print_exc()
        return None, None

if __name__ == "__main__":
    # æ¸¬è©¦ç”¨
    res, hist = load_resources_and_predict()
    if res is not None:
        print(res.head())