# model_service.py
import pandas as pd
import numpy as np
import joblib
import os
import warnings
import json
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow import keras

# ==========================================
# ğŸš‘ [è¨­å®š] æŠ‘åˆ¶è­¦å‘Š & ç›¸å®¹æ€§è¨­å®š
# ==========================================
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=UserWarning)

# ==========================================
# âš™ï¸ è¨­å®šèˆ‡å¸¸æ•¸
# ==========================================
MODEL_FILES = {
    "lgbm": "lgbm_model.pkl",
    "lstm": "lstm_model.keras",
    "scaler_seq": "scaler_seq.pkl",
    "scaler_dir": "scaler_dir.pkl",
    "scaler_target": "scaler_target.pkl",
    "weights": "ensemble_weights.pkl",
    "history_data": "final_training_data_with_humidity.csv"
}

LOOKBACK_HOURS = 168

# ==========================================
# ğŸ› ï¸ ç‰¹å¾µå·¥ç¨‹ (ç¶­æŒåŸæ¨£ï¼ŒåŒ…å« 2025 å‡æ—¥)
# ==========================================
def get_taiwan_holidays():
    """
    å›å‚³å°ç£åœ‹å®šå‡æ—¥åˆ—è¡¨ (æ ¼å¼: YYYY-MM-DD)
    """
    holidays = [
        # --- 2024 ---
        "2024-01-01", "2024-02-08", "2024-02-09", "2024-02-10", "2024-02-11", 
        "2024-02-12", "2024-02-13", "2024-02-14", "2024-02-28", "2024-04-04", 
        "2024-04-05", "2024-05-01", "2024-06-10", "2024-09-17", "2024-10-10",

        # --- 2025 ---
        "2025-01-01", 
        "2025-01-25", "2025-01-26", "2025-01-27", "2025-01-28", "2025-01-29", 
        "2025-01-30", "2025-01-31", "2025-02-01", "2025-02-02",
        "2025-02-28", "2025-03-01", "2025-03-02",
        "2025-04-03", "2025-04-04", "2025-04-05", "2025-04-06",
        "2025-05-01",
        "2025-05-30", "2025-05-31", "2025-06-01",
        "2025-09-27", "2025-09-28", "2025-09-29",
        "2025-10-04", "2025-10-05", "2025-10-06",
        "2025-10-10", "2025-10-11", "2025-10-12",
        "2025-10-24", "2025-10-25", "2025-10-26",
        "2025-12-25"
    ]
    return holidays

def add_lgbm_features(df):
    df = df.copy()
    df["hour"] = df.index.hour
    df["day_of_week"] = df.index.dayofweek
    df["month"] = df.index.month
    
    tw_holidays = get_taiwan_holidays()
    date_strs = df.index.strftime("%Y-%m-%d")
    
    df["is_holiday_or_weekend"] = ((df["day_of_week"] >= 5) | (date_strs.isin(tw_holidays))).astype(int)
    df["is_weekend"] = df["is_holiday_or_weekend"]
    
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24.0)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24.0)
    df["week_sin"] = np.sin(2 * np.pi * df["day_of_week"] / 7.0)
    df["week_cos"] = np.cos(2 * np.pi * df["day_of_week"] / 7.0)
    df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12.0)
    df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12.0)
    
    peak_hours = [10, 11, 12, 13, 14, 15, 17, 18, 19, 20]
    df["is_peak"] = df["hour"].isin(peak_hours).astype(int)
    
    # æ³¨æ„ï¼šé€™è£¡ä¾è³´ 'power' æ¬„ä½
    for lag in [24, 168, 720]:
         if f'lag_{lag}h' not in df.columns: df[f'lag_{lag}h'] = df["power"].shift(lag)
    for i in [1, 2, 3]:
        if f'temp_lag_{i}' not in df.columns: df[f'temp_lag_{i}'] = df["temperature"].shift(i)
    for window_days in [7, 14, 30]:
        window_hours = window_days * 24
        df[f'ma_{window_days}d'] = df["power"].shift(1).rolling(window=window_hours, min_periods=1).mean()
        df[f'std_{window_days}d'] = df["power"].shift(1).rolling(window=window_hours, min_periods=1).std()
    
    df["temp_x_peak"] = df["temperature"] * df["is_peak"]
    df["temp_squared"] = df["temperature"] ** 2
    return df

def add_lstm_features(df):
    df = df.copy()
    df["hour"] = df.index.hour.astype(float)
    
    tw_holidays = get_taiwan_holidays()
    date_strs = df.index.strftime("%Y-%m-%d")
    
    df["is_weekend"] = ((df.index.dayofweek >= 5) | (date_strs.isin(tw_holidays))).astype(float)
    df["day_of_week"] = df.index.dayofweek.astype(float)
    
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24.0)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24.0)
    df["week_sin"] = np.sin(2 * np.pi * df["day_of_week"] / 7.0)
    df["week_cos"] = np.cos(2 * np.pi * df["day_of_week"] / 7.0)
    df["temp_squared"] = df["temperature"] ** 2
    
    df["lag_24h"] = df["power"].shift(24)
    df["lag_168h"] = df["power"].shift(168)
    df["rolling_mean_24h_safe"] = df["power"].shift(24).rolling(window=24, min_periods=1).mean()
    df["rolling_std_24h_safe"] = df["power"].shift(24).rolling(window=24, min_periods=1).std()
    df["rolling_mean_168h"] = df["power"].shift(24).rolling(window=168, min_periods=1).mean()
    df["rolling_std_168h"] = df["power"].shift(24).rolling(window=168, min_periods=1).std()
    return df

# ==========================================
# ğŸ§  ä¸»é æ¸¬æµç¨‹ (IO å„ªåŒ–ç‰ˆ)
# ==========================================
def load_resources_and_predict(full_data_df=None):
    """
    åŸ·è¡Œé æ¸¬æµç¨‹ã€‚
    åƒæ•¸:
      full_data_df (pd.DataFrame): 
        å¾ app_utils è¼‰å…¥çš„å®Œæ•´æ­·å²è³‡æ–™ã€‚
        è‹¥ç‚º Noneï¼Œå‰‡è‡ªå‹•å˜—è©¦è®€å–æœ¬åœ° CSV (Fallback æ¨¡å¼)ã€‚
    """
    resources = {}
    try:
        # 1. è¼‰å…¥æ¨¡å‹è³‡æº
        resources['lgbm'] = joblib.load(MODEL_FILES['lgbm'])
        resources['lstm'] = keras.models.load_model(MODEL_FILES['lstm'])
        resources['scaler_seq'] = joblib.load(MODEL_FILES['scaler_seq'])
        resources['scaler_dir'] = joblib.load(MODEL_FILES['scaler_dir'])
        resources['scaler_target'] = joblib.load(MODEL_FILES['scaler_target'])
        resources['weights'] = joblib.load(MODEL_FILES['weights'])
        
        # 2. æº–å‚™æ•¸æ“š (å„ªå…ˆä½¿ç”¨å‚³å…¥çš„ DataFrame)
        combined_df = None
        
        if full_data_df is not None and not full_data_df.empty:
            print("ğŸ“¥ [Model Service] ä½¿ç”¨è¨˜æ†¶é«”ä¸­çš„ DataFrame é€²è¡Œé æ¸¬...")
            combined_df = full_data_df.copy()
        else:
            print("âš ï¸ [Model Service] æœªæ”¶åˆ°æ•¸æ“šï¼Œå•Ÿå‹• Fallback æ¨¡å¼ï¼šè®€å–æœ¬åœ° CSV...")
            if not os.path.exists(MODEL_FILES['history_data']):
                print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {MODEL_FILES['history_data']}")
                return None, None
            
            hist_df = pd.read_csv(MODEL_FILES['history_data'])
            
            # æ™‚é–“æ ¼å¼æ¨™æº–åŒ–
            if 'datetime' in hist_df.columns:
                 hist_df['timestamp'] = pd.to_datetime(hist_df['datetime'])
            elif 'timestamp' in hist_df.columns:
                 hist_df['timestamp'] = pd.to_datetime(hist_df['timestamp'])
            
            hist_df = hist_df.set_index('timestamp').sort_index()
            
            # æ¬„ä½åç¨±æ¨™æº–åŒ–
            if 'power' in hist_df.columns: 
                hist_df = hist_df.rename(columns={'power': 'power_kW'})
                
            combined_df = hist_df
            
        # 3. è³‡æ–™æ¬„ä½æª¢æŸ¥èˆ‡å°é½Š (é—œéµä¿®æ­£)
        # æ¨¡å‹è¨“ç·´æ™‚ç”¨çš„æ˜¯ 'power'ï¼Œä½† app å¯èƒ½å‚³ä¾† 'power_kW'
        if 'power_kW' in combined_df.columns:
            combined_df['power'] = pd.to_numeric(combined_df['power_kW'], errors='coerce')
        elif 'power' in combined_df.columns:
            combined_df['power'] = pd.to_numeric(combined_df['power'], errors='coerce')
        else:
            print("âŒ éŒ¯èª¤ï¼šæ•¸æ“šä¸­æ‰¾ä¸åˆ° power æˆ– power_kW æ¬„ä½")
            return None, None
            
        combined_df = combined_df.dropna(subset=['power'])
        
        # 4. é æ¸¬æº–å‚™ (åŸºæº–æ™‚é–“ç‚ºæ•¸æ“šæœ€å¾Œä¸€ç­†)
        # ç‚ºäº†ç‰¹å¾µå·¥ç¨‹ (Lags, Rolling)ï¼Œæˆ‘å€‘éœ€è¦ä¿ç•™æœ€å¾Œä¸€æ®µå¤ é•·çš„æ­·å²æ•¸æ“š
        buffer_size = 2000 
        df_ready = combined_df.iloc[-buffer_size:].copy()
        
        last_time = df_ready.index[-1]
        print(f"ğŸ”® é æ¸¬åŸºæº–æ™‚é–“ (Last Data Point): {last_time}")
        
        # ç”¢ç”Ÿæœªä¾† 24 å°æ™‚çš„æ™‚é–“æˆ³è¨˜
        future_dates = [last_time + timedelta(hours=i+1) for i in range(24)]
        future_df = pd.DataFrame(index=future_dates, columns=df_ready.columns)
        
        # å¡«è£œæœªä¾†å¤©æ°£ (é€™è£¡åšç°¡å–®å‡è¨­ï¼Œå¯¦å‹™ä¸Šæ‡‰æ¥æ°£è±¡ API)
        if 'temperature' in df_ready.columns:
            future_df['temperature'] = df_ready['temperature'].iloc[-1]
        else:
            future_df['temperature'] = 25.0
            
        if 'humidity' in df_ready.columns:
            future_df['humidity'] = df_ready['humidity'].iloc[-1]
        else:
             future_df['humidity'] = 70.0
        
        # åˆä½µæ­·å²èˆ‡æœªä¾†ï¼Œé€²è¡Œç‰¹å¾µå·¥ç¨‹
        full_context = pd.concat([df_ready, future_df])
        
        # 5. ç‰¹å¾µå·¥ç¨‹
        df_lgbm = add_lgbm_features(full_context)
        df_lstm = add_lstm_features(full_context)
        
        # å–å‡ºæœªä¾† 24 é»çš„ç‰¹å¾µ
        target_feat_lgbm = df_lgbm.iloc[-24:]
        # LSTM çš„è¼¸å…¥æº–å‚™æ¯”è¼ƒè¤‡é›œï¼Œéœ€è¦ Sequence Data
        target_feat_lstm = df_lstm.iloc[-24:] # é€™è£¡ä¸»è¦ç”¨å®ƒçš„ index æˆ–è¼”åŠ©ç‰¹å¾µ
        
        # --- LGBM æ¨è«– ---
        lgbm_feature_names = resources['lgbm'].feature_name()
        X_lgbm = target_feat_lgbm[lgbm_feature_names]
        pred_lgbm = resources['lgbm'].predict(X_lgbm)
        
        # --- LSTM æ¨è«– ---
        # ç›®å‰æ™‚é–“é» index (ç›¸å°æ–¼ full_context)
        # æˆ‘å€‘è¦é æ¸¬çš„æ˜¯æœ€å¾Œ 24 ç­†ï¼Œæ‰€ä»¥è¦æ‹¿é€™ 24 ç­†ä¹‹å‰çš„ Sequence
        # ä½†é€™è£¡æ˜¯ç°¡åŒ–ç‰ˆï¼šæˆ‘å€‘åªé æ¸¬æœªä¾†çš„ç¬¬ä¸€å€‹é»ï¼Œç„¶å¾Œè¿­ä»£? 
        # æˆ–æ˜¯å¦‚æœä½ çš„ LSTM æ˜¯ Many-to-Many ä¸€æ¬¡å 24 é»?
        # æ ¹æ“šåŸæœ¬ç¨‹å¼ç¢¼é‚è¼¯ï¼Œé€™è£¡ä¼¼ä¹æ˜¯åšä¸€å€‹æ™‚é–“é»çš„æ¨è«–ï¼Œæˆ–è€…æ‰¹æ¬¡æ¨è«–ã€‚
        # é€™è£¡ç¶­æŒåŸæœ¬é‚è¼¯ï¼š
        
        current_idx = -25 # æœªä¾†çš„ç¬¬ä¸€å€‹é»çš„å‰ä¸€å€‹ä½ç½® (ä¹Ÿå°±æ˜¯æ­·å²æœ€å¾Œä¸€é»)
        
        seq_cols = ["power", "temperature", "humidity", "hour_sin", "hour_cos", "is_weekend"]
        dir_cols = ["lag_24h", "lag_168h", "temperature", "humidity", "hour_sin", "hour_cos", "week_sin", "week_cos", "is_weekend", "temp_squared", "rolling_mean_24h_safe", "rolling_std_24h_safe", "rolling_mean_168h", "rolling_std_168h"]
        
        # è£œé½Š LSTM å¯èƒ½ç¼ºå°‘çš„æ¬„ä½
        for c in seq_cols + dir_cols:
            if c not in df_lstm.columns: df_lstm[c] = 0
        
        # æº–å‚™è¼¸å…¥è³‡æ–™ (é€™è£¡é‚è¼¯æ˜¯å–æœ€å¾Œä¸€æ®µæ­·å²ä¾†é æ¸¬æœªä¾†)
        # æ³¨æ„ï¼šåŸæœ¬çš„ code ä¼¼ä¹åªé æ¸¬äº†ä¸€æ¬¡(æˆ–ä¸€å€‹batch)ã€‚
        # ç‚ºäº†ç¢ºä¿ç¶­åº¦æ­£ç¢ºï¼Œé€™è£¡ç›´æ¥æ²¿ç”¨åŸç‰ˆé‚è¼¯
        seq_data = df_lstm[seq_cols].iloc[current_idx-LOOKBACK_HOURS+1 : current_idx+1]
        dir_data = df_lstm[dir_cols].iloc[current_idx+1 : current_idx+2]
        
        X_seq = resources['scaler_seq'].transform(seq_data).reshape(1, LOOKBACK_HOURS, -1)
        X_dir = resources['scaler_dir'].transform(dir_data)
        
        pred_lstm_scaled = resources['lstm'].predict([X_seq, X_dir], verbose=0)
        pred_lstm_val = resources['scaler_target'].inverse_transform(pred_lstm_scaled).flatten()[0]
        
        # è‹¥ LSTM åªåä¸€å€‹å€¼ï¼Œé€™è£¡ç°¡å–®å°‡å…¶å»£æ’­åˆ° 24 å°æ™‚ (æˆ–æ˜¯ä¾å¾ª daily pattern)
        # ç‚ºäº†èˆ‡ LGBM (24é») å½¢ç‹€åŒ¹é…
        pred_lstm = np.full(24, pred_lstm_val) 
        
        # --- é›†æˆ (Ensemble) ---
        pred_final = (pred_lgbm * resources['weights']['w_lgbm']) + (pred_lstm * resources['weights']['w_lstm'])
        
        # 6. æ‰“åŒ…çµæœ
        result_df = pd.DataFrame({
            "æ™‚é–“": future_dates,
            "é æ¸¬å€¼": pred_final,
            "LGBM": pred_lgbm,
            "LSTM": pred_lstm
        }).set_index("æ™‚é–“")
        
        return result_df, combined_df
        
    except Exception as e:
        print(f"âŒ [Model Service Error]: {e}")
        import traceback
        traceback.print_exc()
        return None, None