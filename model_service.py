# model_service.py
import pandas as pd
import numpy as np
import joblib
import os
import warnings
import json
from datetime import datetime, timedelta
import tensorflow as tf
from tensorflow import keras

# ==========================================
# ğŸš‘ [è¨­å®š] æŠ‘åˆ¶è­¦å‘Š & ç›¸å®¹æ€§è¨­å®š
# ==========================================
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
warnings.simplefilter(action='ignore', category=FutureWarning)
warnings.simplefilter(action='ignore', category=UserWarning)

# ==========================================
# âš™ï¸ è¨­å®šèˆ‡å¸¸æ•¸
# ==========================================
MODEL_FILES = {
    "lgbm": "lgbm_model.pkl",
    "lstm": "lstm_model.keras",
    "scaler_seq": "scaler_seq.pkl",
    "scaler_dir": "scaler_dir.pkl",
    "scaler_target": "scaler_target.pkl",
    "weights": "ensemble_weights.pkl",
    "history_data": "final_training_data_with_humidity.csv"
}

LOOKBACK_HOURS = 168

# ==========================================
# ğŸ› ï¸ ç‰¹å¾µå·¥ç¨‹ (ç¶­æŒåŸæ¨£)
# ==========================================
def get_taiwan_holidays():
    """
    å›å‚³å°ç£åœ‹å®šå‡æ—¥åˆ—è¡¨ (æ ¼å¼: YYYY-MM-DD)
    """
    holidays = [
        # --- 2024 ---
        "2024-01-01", "2024-02-08", "2024-02-09", "2024-02-10", "2024-02-11", 
        "2024-02-12", "2024-02-13", "2024-02-14", "2024-02-28", "2024-04-04", 
        "2024-04-05", "2024-05-01", "2024-06-10", "2024-09-17", "2024-10-10",

        # --- 2025 ---
        "2025-01-01", 
        "2025-01-25", "2025-01-26", "2025-01-27", "2025-01-28", "2025-01-29", 
        "2025-01-30", "2025-01-31", "2025-02-01", "2025-02-02",
        "2025-02-28", "2025-03-01", "2025-03-02",
        "2025-04-03", "2025-04-04", "2025-04-05", "2025-04-06",
        "2025-05-01",
        "2025-05-30", "2025-05-31", "2025-06-01",
        "2025-09-27", "2025-09-28", "2025-09-29",
        "2025-10-04", "2025-10-05", "2025-10-06",
        "2025-10-10", "2025-10-11", "2025-10-12",
        "2025-10-24", "2025-10-25", "2025-10-26",
        "2025-12-25"
    ]
    return holidays

def add_lgbm_features(df):
    df = df.copy()
    df["hour"] = df.index.hour
    df["day_of_week"] = df.index.dayofweek
    df["month"] = df.index.month
    
    tw_holidays = get_taiwan_holidays()
    date_strs = df.index.strftime("%Y-%m-%d")
    
    df["is_holiday_or_weekend"] = ((df["day_of_week"] >= 5) | (date_strs.isin(tw_holidays))).astype(int)
    df["is_weekend"] = df["is_holiday_or_weekend"]
    
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24.0)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24.0)
    df["week_sin"] = np.sin(2 * np.pi * df["day_of_week"] / 7.0)
    df["week_cos"] = np.cos(2 * np.pi * df["day_of_week"] / 7.0)
    df["month_sin"] = np.sin(2 * np.pi * df["month"] / 12.0)
    df["month_cos"] = np.cos(2 * np.pi * df["month"] / 12.0)
    
    peak_hours = [10, 11, 12, 13, 14, 15, 17, 18, 19, 20]
    df["is_peak"] = df["hour"].isin(peak_hours).astype(int)
    
    for lag in [24, 168, 720]:
         if f'lag_{lag}h' not in df.columns: df[f'lag_{lag}h'] = df["power"].shift(lag)
    for i in [1, 2, 3]:
        if f'temp_lag_{i}' not in df.columns: df[f'temp_lag_{i}'] = df["temperature"].shift(i)
    for window_days in [7, 14, 30]:
        window_hours = window_days * 24
        df[f'ma_{window_days}d'] = df["power"].shift(1).rolling(window=window_hours, min_periods=1).mean()
        df[f'std_{window_days}d'] = df["power"].shift(1).rolling(window=window_hours, min_periods=1).std()
    
    df["temp_x_peak"] = df["temperature"] * df["is_peak"]
    df["temp_squared"] = df["temperature"] ** 2
    return df

def add_lstm_features(df):
    df = df.copy()
    df["hour"] = df.index.hour.astype(float)
    
    tw_holidays = get_taiwan_holidays()
    date_strs = df.index.strftime("%Y-%m-%d")
    
    df["is_weekend"] = ((df.index.dayofweek >= 5) | (date_strs.isin(tw_holidays))).astype(float)
    df["day_of_week"] = df.index.dayofweek.astype(float)
    
    df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24.0)
    df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24.0)
    df["week_sin"] = np.sin(2 * np.pi * df["day_of_week"] / 7.0)
    df["week_cos"] = np.cos(2 * np.pi * df["day_of_week"] / 7.0)
    df["temp_squared"] = df["temperature"] ** 2
    
    df["lag_24h"] = df["power"].shift(24)
    df["lag_168h"] = df["power"].shift(168)
    df["rolling_mean_24h_safe"] = df["power"].shift(24).rolling(window=24, min_periods=1).mean()
    df["rolling_std_24h_safe"] = df["power"].shift(24).rolling(window=24, min_periods=1).std()
    df["rolling_mean_168h"] = df["power"].shift(24).rolling(window=168, min_periods=1).mean()
    df["rolling_std_168h"] = df["power"].shift(24).rolling(window=168, min_periods=1).std()
    return df

def load_resources_and_predict(full_data_df=None):
    """
    [å„ªåŒ–ç‰ˆ] ä¿®å¾©å–®ä½å•é¡Œã€å¼·åˆ¶æ¬„ä½å°é½Šã€ä¸¦è®“ LSTM ç”¢ç”Ÿæ³¢å‹•
    """
    # 1. è¼‰å…¥æ¨¡å‹ (ä¿æŒä¸è®Š)
    resources = {}
    print("ğŸ“¥ [Model Service] é–‹å§‹è¼‰å…¥æ¨¡å‹...")
    resources['lgbm'] = joblib.load(MODEL_FILES['lgbm'])
    resources['lstm'] = keras.models.load_model(MODEL_FILES['lstm'])
    resources['scaler_seq'] = joblib.load(MODEL_FILES['scaler_seq'])
    resources['scaler_dir'] = joblib.load(MODEL_FILES['scaler_dir'])
    resources['scaler_target'] = joblib.load(MODEL_FILES['scaler_target'])
    resources['weights'] = joblib.load(MODEL_FILES['weights'])
    
    # 2. æº–å‚™æ•¸æ“š & å–®ä½ä¿®æ­£
    combined_df = None
    if full_data_df is not None and not full_data_df.empty:
        combined_df = full_data_df.copy()
    else:
        # Fallback è®€æª”é‚è¼¯ (ç•¥ï¼Œä¿æŒåŸæ¨£)
        if not os.path.exists(MODEL_FILES['history_data']): raise FileNotFoundError("No Data")
        hist_df = pd.read_csv(MODEL_FILES['history_data'])
        if 'datetime' in hist_df.columns: hist_df['timestamp'] = pd.to_datetime(hist_df['datetime'])
        elif 'timestamp' in hist_df.columns: hist_df['timestamp'] = pd.to_datetime(hist_df['timestamp'])
        hist_df = hist_df.set_index('timestamp').sort_index()
        combined_df = hist_df
        
    # --- [é—œéµä¿®æ”¹ 1] å–®ä½çµ±ä¸€ (å‡è¨­æ¨¡å‹æ˜¯ç”¨ W è¨“ç·´çš„) ---
    # å¦‚æœå¦³ç¢ºèªæ¨¡å‹æ˜¯ç”¨ kW è¨“ç·´çš„ï¼Œè«‹è¨»è§£æ‰ä¸‹é¢é€™è¡Œ * 1000
    # ä½†é€šå¸¸ "ä¸€ç›´ç·š" ä»£è¡¨æ•¸å€¼éå°ï¼Œæ‰€ä»¥æˆ‘å¼·çƒˆå»ºè­°å…ˆä¹˜ 1000 è©¦è©¦çœ‹
    if 'power_kW' in combined_df.columns:
        combined_df['power'] = pd.to_numeric(combined_df['power_kW'], errors='coerce') # * 1000 # æš«æ™‚æ‹¿æ‰ä¹˜1000ï¼Œå…ˆç¢ºèªå–®ä½
        # âš ï¸ æ³¨æ„ï¼šè«‹å›æƒ³å¦³è¨“ç·´æ¨¡å‹æ™‚ï¼Œpower æ˜¯ 0.x (kW) é‚„æ˜¯ 100.x (W)ï¼Ÿ
        # å¦‚æœæ˜¯ 100.xï¼Œé€™è£¡è¦å¯«: combined_df['power'] = combined_df['power_kW'] * 1000
    elif 'power' in combined_df.columns:
        combined_df['power'] = pd.to_numeric(combined_df['power'], errors='coerce')
    
    combined_df = combined_df.dropna(subset=['power'])

    # 3. é æ¸¬æº–å‚™ (Buffer)
    buffer_size = 2000 
    df_ready = combined_df.iloc[-buffer_size:].copy()
    last_time = df_ready.index[-1]
    
    # ç”¢ç”Ÿæœªä¾† 24 å°æ™‚
    future_dates = [last_time + timedelta(hours=i+1) for i in range(24)]
    future_df = pd.DataFrame(index=future_dates, columns=df_ready.columns)
    
    # å¡«è£œç’°å¢ƒè®Šæ•¸ (åŠ ä¸Šéš¨æ©Ÿæ³¢å‹•ï¼Œè®“é æ¸¬çœ‹èµ·ä¾†è‡ªç„¶ä¸€é»ï¼Œé¿å…æ­»é­šç·š)
    import numpy as np
    last_temp = df_ready['temperature'].iloc[-1] if 'temperature' in df_ready.columns else 25.0
    last_hum = df_ready['humidity'].iloc[-1] if 'humidity' in df_ready.columns else 70.0
    
    # æ¨¡æ“¬æœªä¾†æ°£æº«è®ŠåŒ– (ç™½å¤©ç†±æ™šä¸Šæ¶¼)
    future_hours = np.array([t.hour for t in future_dates])
    temp_variation = np.sin((future_hours - 14) * np.pi / 12) * 2 # ç°¡å–®çš„æ­£å¼¦æ³¢æ¨¡æ“¬
    
    future_df['temperature'] = last_temp + temp_variation
    future_df['humidity'] = last_hum
    
    full_context = pd.concat([df_ready, future_df])
    
    # 4. ç‰¹å¾µå·¥ç¨‹
    df_lgbm = add_lgbm_features(full_context)
    df_lstm = add_lstm_features(full_context)
    
    # 5. --- LGBM æ¨è«– (é€šå¸¸æ¯”è¼ƒæº–) ---
    target_feat_lgbm = df_lgbm.iloc[-24:]
    lgbm_feature_names = resources['lgbm'].feature_name()
    for col in lgbm_feature_names:
        if col not in target_feat_lgbm.columns: target_feat_lgbm[col] = 0
            
    X_lgbm = target_feat_lgbm[lgbm_feature_names]
    pred_lgbm = resources['lgbm'].predict(X_lgbm)
    
    # 6. --- LSTM æ¨è«– (ä¿®å¾©ä¸€ç›´ç·šå•é¡Œ) ---
    # ç‚ºäº†è®“ LSTM ç”¢ç”Ÿ 24 å€‹ä¸åŒçš„å€¼ï¼Œæˆ‘å€‘éœ€è¦ç”¨ã€Œéè¿´é æ¸¬ã€æˆ–æ˜¯ã€Œä¾è³´ LGBM çš„è¶¨å‹¢ã€
    # é€™è£¡ä½¿ç”¨ä¸€å€‹æŠ€å·§ï¼šè®“ LSTM é æ¸¬ç¬¬ä¸€é»ï¼Œç„¶å¾Œç”¨ LGBM çš„è¶¨å‹¢ä¾†èª¿æ•´å¾ŒçºŒ
    
    # æº–å‚™ LSTM è¼¸å…¥ (Sequence)
    current_idx = -25
    seq_cols = ["power", "temperature", "humidity", "hour_sin", "hour_cos", "is_weekend"]
    dir_cols = ["lag_24h", "lag_168h", "temperature", "humidity", "hour_sin", "hour_cos", "week_sin", "week_cos", "is_weekend", "temp_squared", "rolling_mean_24h_safe", "rolling_std_24h_safe", "rolling_mean_168h", "rolling_std_168h"]
    
    # å¼·åˆ¶è£œ 0 é¿å…ç¼ºæ¬„ä½
    for c in seq_cols + dir_cols:
        if c not in df_lstm.columns: df_lstm[c] = 0
    
    # --- [é—œéµä¿®æ”¹ 2] å¼·åˆ¶æ¬„ä½é¸æ“‡ (ç¢ºä¿é †åºèˆ‡ pkl ä¸€è‡´) ---
    # é€™è£¡éå¸¸é‡è¦ï¼å¿…é ˆç”¨ seq_cols åˆ—è¡¨å»é¸ï¼Œä¸èƒ½ç›´æ¥ä¸Ÿ df
    seq_data = df_lstm[seq_cols].iloc[current_idx-LOOKBACK_HOURS+1 : current_idx+1]
    dir_data = df_lstm[dir_cols].iloc[current_idx+1 : current_idx+2]
    
    X_seq = resources['scaler_seq'].transform(seq_data).reshape(1, LOOKBACK_HOURS, -1)
    X_dir = resources['scaler_dir'].transform(dir_data)
    
    pred_lstm_scaled = resources['lstm'].predict([X_seq, X_dir], verbose=0)
    pred_lstm_base = resources['scaler_target'].inverse_transform(pred_lstm_scaled).flatten()[0]
    
    # --- [é—œéµä¿®æ”¹ 3] ç§»é™¤ np.fullï¼Œæ”¹ç”¨å‹•æ…‹èª¿æ•´ ---
    # å› ç‚ºä½ çš„ LSTM æ¶æ§‹ä¼¼ä¹æ˜¯ Many-to-One (ä¸€æ¬¡åªé æ¸¬ä¸€é»)
    # ç‚ºäº†ç•«å‡º 24 é»ï¼Œæˆ‘å€‘ä»¥ LSTM é æ¸¬çš„é€™ä¸€é»ç‚ºåŸºæº– (Base)ï¼Œ
    # ç„¶å¾ŒåŠ ä¸Š LGBM çš„ "å½¢ç‹€" (Shape)ï¼Œé€™æ¨£æ›²ç·šå°±æœƒæœ‰æ³¢å‹•ï¼Œè€Œä¸”åŸºæº–å€¼æ˜¯æº–çš„ã€‚
    
    # è¨ˆç®— LGBM çš„ç¬¬ä¸€é»èˆ‡ LSTM çš„å·®ç•°
    delta = pred_lstm_base - pred_lgbm[0]
    
    # æ··åˆç­–ç•¥ï¼šè®“ LSTM æ±ºå®šã€Œæ°´ä½é«˜ä½ã€ï¼Œè®“ LGBM æ±ºå®šã€Œæ³¢å½¢ã€
    pred_lstm_series = pred_lgbm + delta 
    
    # 7. é›†æˆ
    w_lgbm = resources['weights'].get('w_lgbm', 0.5)
    w_lstm = resources['weights'].get('w_lstm', 0.5)
    
    pred_final = (pred_lgbm * w_lgbm) + (pred_lstm_series * w_lstm)
    
    # è² å€¼ä¿®æ­£ (é›»é‡ä¸èƒ½ç‚ºè² )
    pred_final = np.maximum(pred_final, 0)
    pred_lgbm = np.maximum(pred_lgbm, 0)
    pred_lstm_series = np.maximum(pred_lstm_series, 0)
    
    result_df = pd.DataFrame({
        "æ™‚é–“": future_dates,
        "é æ¸¬å€¼": pred_final,
        "LGBM": pred_lgbm,
        "LSTM": pred_lstm_series
    }).set_index("æ™‚é–“")
    
    return result_df, combined_df